\documentclass[]{article}
\usepackage{etex}
\usepackage[margin = 1.5in]{geometry}
\setlength{\parindent}{0in}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{color}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage[lined]{algorithm2e}
\usepackage{qtree}
\usepackage{xytree}
\usepackage{float}
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}
\usepackage[pdftex,
  pdfauthor={Michael Noukhovitch},
  pdftitle={CS 341: Algorithms},
  pdfsubject={Lecture notes from CS 341 at the University of Waterloo},
  pdfproducer={LaTeX},
  pdfcreator={pdflatex}]{hyperref}

\usepackage{cleveref}
\usepackage{enumitem}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4
}

\theoremstyle{definition}
\newtheorem*{defn}{Definition}
\newtheorem{ex}{Example}[section]
\newtheorem*{theorem}{Theorem}

\setlength{\marginparwidth}{1.5in}
\setlength{\algomargin}{0.75em}

\DeclarePairedDelimiter{\set}{\lbrace}{\rbrace}

\definecolor{darkish-blue}{RGB}{25,103,185}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=darkish-blue,
    filecolor=darkish-blue,
    linkcolor=darkish-blue,
    urlcolor=darkish-blue
}
\newcommand{\lecture}[1]{\marginpar{{\footnotesize $\leftarrow$ \underline{#1}}}}

\makeatletter
\def\blfootnote{\gdef\@thefnmark{}\@footnotetext}
\makeatother

\begin{document}
	\let\ref\Cref

	\title{\bf{CS 341: Algorithms}}
	\date{Winter 2015, University of Waterloo \\ \center Notes written from Timothy Chan's lectures.}
	\author{Michael Noukhovitch}

	\maketitle
	\newpage
	\tableofcontents
	\newpage

	\section{Introduction}
		\subsection{Algorithm Analysis}
			\textbf{analysis}: determine if algorithm is correct and efficient \\
			\textbf{correct}: formal proof using loop invariant \\
			\textbf{efficient}: solving in polynomial time \textit{(usually)}
		\subsection{Maximum Problem}
			Find the largest element in an array
			\begin{lstlisting}{language=python}
	max = list[0]
	for i in list[1:]:
		if i > max:
			max = i
	return max
			\end{lstlisting}		
		\subsection{3SUM Problem}
	\section{Math Review}
		\subsection{Asymptotic Notation}
			\begin{defn}[O]
				upper bound ($\le$) \\
				$f(n) = O(g(n))$ if $\exists$ constants $c > 0, n_0 > 0$ such that $f(n) \le c \cdot g(n) \ \forall n \ge n_0$
			\end{defn}

			\begin{defn}[$\Omega$]
				lower bound ($\ge$) \\
				$f(n) = \Omega(g(n))$ if $\exists$ constants $c > 0, n_0 > 0$ such that $f(n) \ge c \cdot g(n) \ \forall n \ge n_0$
			\end{defn}

			\begin{defn}[$\Theta$]
				tight bound ($=$) \\
				$f(n) = \Theta(g(n))$ if $\exists$ constants $c_1, c_2 > 0, n_0 > 0$ such that $c_1 \cdot g(n) \le f(n) \le c_2 \cdot g(n) \ \forall n \ge n_0$
			\end{defn}

			\begin{defn}[o]
				loose upper bound ($<$) \\
				$f(n) = o(g(n))$ if $\forall$ constants $c > 0, \ \exists$ constant $n_0 > 0$ such that $f(n) < c \cdot g(n) \ \forall n \ge n_0$
			\end{defn}

			\begin{defn}[$\omega$]
				loose lower bound ($>$) \\
				$f(n) = \omega(g(n))$ if $\forall$ constants $c > 0 \ \exists$ constant $n_0 > 0$ such that $f(n) > c \cdot g(n) \ \forall n \ge n_0$
			\end{defn}
		\subsection{Asymptotic Tricks}	
			$f(n) \in o(g(n)) \iff \lim_{n \to \infty} \frac{f(n)}{g(n)} = 0$ \\
			$f(n) \in \omega(g(n)) \iff \lim_{n \to \infty} \frac{f(n)}{g(n)} = \infty$ \\
			$f(n) \in O(g(n)) \iff \lim_{n \to \infty} \frac{f(n)}{g(n)} < \infty$ \\
			$f(n) \in \Omega(g(n)) \iff \lim_{n \to \infty} \frac{f(n)}{g(n)} > 0$ \\
		\subsection{Summations}
			$\sum\limits_{i=1}^n i^d = \Theta(n^{d+1})$ for any constant $d > -1$ \\ \\
			$
				\sum\limits_{i=0}^n c^i = \frac{c^{n+1}-1}{c-1} = 
				\begin{cases}
					\Theta(c^n) & $ for all constants $c > 1 \\
					\Theta(1) & $ for all constants $c < 1 \\
				\end{cases}
			$ \\ \\
			$\sum\limits_{i=1}^n \frac{1}{i} = 1 \cdot \ln(n) + \Theta(1)$ \\ \\
			$\sum\limits_{i=1}^n \log(i) = n \log(n) = \Theta(n)$
		\subsection{Recurrences}
			\subsubsection{Recursion Tree Method}
				Break down our recursion into a tree with each child node being a recursion. Find the cost of each child and sum across the level
				\begin{ex}
					$T(n) = 
					\begin{cases}
						2T(\frac{n}{2}) + n^2 & \mbox{if } n > 1 \\
						7 & \mbox{if } n=1	
					\end{cases}
					$
				\end{ex}
				\begin{tabular}{l | c}
					level 0 & $n^2$ \\
					level 1 & $2 \cdot \frac{n^2}{4} = \frac{n^2}{2}$ \\
					level 2	& $4 \cdot \frac{n^2}{16} = \frac{n^2}{4}$ \\
					... & ... \\
					level k & $\frac{n^2}{2^k}$ \\
				\end{tabular}	\\ \\			
				level $k$ must match our base case, so:
				\begin{flalign*}
					\frac{n^2}{2^k} &= 7 & \\
					k &= \log_{2}\frac{n^2}{7} & \\
					\text{ So we get } & \\				
					T(n) &= n^2\sum\limits_{i=0}^k (\frac{1}{2^i}) &\\
					&= n^2 + 7n & \\
					&= O(n^2) &
				\end{flalign*}			
			\subsubsection{Master Method}
				Lookup the answer knowing that your algorithm is expressed as: 
				$T(n) =
				\begin{cases}
					aT(\frac{n}{b}) + f(n) & \mbox{if } n > n_0 \\
					c & \mbox{else} \\
				\end{cases} 
				$
				Set $d = \log_{b}a$ and we end up with three cases:
				\begin{enumerate}
					\item $f(n) \in O(n^{d-\epsilon}) \Rightarrow T(n) \in \Theta(n^d)$
					\item $f(n) \in \Theta(n^{d}) \Rightarrow T(n) \in \Theta(n^{d}\log n)$
					\item $f(n) \in \Omega(n^{d+\epsilon}) \Rightarrow T(n) \in \Theta(f(n))$
				\end{enumerate}
				\begin{ex}
					$a=2,\ b=2,\ f(n) = n^2$ \\
					$d = 1$ \\
					$n^2 \in \Omega(n^{1 + \epsilon}) \therefore T(n) \in \Theta(n^2)$ 
				\end{ex}
							
\end{document}
